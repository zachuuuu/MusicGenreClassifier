#  Music Genre Classifier

Celem projektu jest stworzenie i por贸wnanie dw贸ch architektur sieci neuronowych (MLP oraz CNN) do klasyfikacji gatunk贸w muzycznych na podstawie zbioru danych **GTZAN**.


##  Dataset
Wykorzystano zbi贸r **GTZAN Genre Collection**
* **Liczba utwor贸w:** 1000 (po 100 na gatunek).
* **Format:** Pliki .wav, 30 sekund, 22050Hz.
* **Gatunki (10):** Blues, Classical, Country, Disco, Hiphop, Jazz, Metal, Pop, Reggae, Rock.


## Zastosowane Podejcia

W projekcie zaimplementowano dwie r贸偶ne cie偶ki przetwarzania danych i architektury modeli:

### 1. Podejcie oparte na cechach (Feature-based MLP)
* **Preprocessing:**
    * Ekstrakcja 57 cech audio: MFCC (40), Spectral Features (4), Tempo (1), Chroma (12).
    * Standaryzacja danych (`StandardScaler`).
    * Redukcja wymiarowoci za pomoc **PCA** do 30 g贸wnych komponent贸w (zachowano ~93% wariancji).
* **Architektura:**
    * Wielowarstwowy Perceptron (MLP) z dynamicznie dobieran liczb warstw ukrytych (konfigurowalna przez tuning).
    * Regularyzacja: **Dropout**, **BatchNorm**, **Weight Decay**, **Early Stopping**.
* **Wyniki:** Accuracy na zbiorze testowym: **~68%**.

### 2. Podejcie oparte na obrazie (Spectrogram CNN)
* **Preprocessing:**
    * Generowanie **Mel-spektrogram贸w**.
    * Konwersja do skali decybelowej (dB).
    * Augmentacja danych w czasie rzeczywistym: **Time Masking** oraz **Frequency Masking** (SpecAugment).
* **Architektura:**
    * Konwolucyjna Sie Neuronowa (CNN) z dynamiczn budow warstw konwolucyjnych (konfigurowalna przez tuning).
    * Wykorzystanie **Adaptive Average Pooling**, co pozwala na drastyczn redukcj parametr贸w i uniezale偶nienie od dugoci wejcia.
    * Regularyzacja: **Dropout**, **BatchNorm**, **Weight Decay**, **Early Stopping**.
* **Wyniki:** (Accuracy na zbiorze testowym **~85%**).

## Instalacja i Uruchomienie

### 1. Instalacja zale偶noci
```bash
pip install -r requirements.txt
```

### 2. Przygotowanie danych (Preprocessing)
Skrypt pobiera surowe dane audio, generuje plik CSV z cechami oraz katalog ze spektrogramami.
```bash
python -m performing_data.preprocess
```

### 3. Trening modeli (Standardowy)
Uruchomienie treningu z parametrami zdefiniowanymi w config.py

**Dla modelu MLP**:
```bash
python -m models.train --model mlp
```

**Dla modelu CNN**:
```bash
python -m models.train --model cnn
```
Wyniki (wykresy, macierze pomyek, model .weights.h5 + metadata) zostan zapisane w folderze models/(mlp/cnn)/reports/


### 4. Hyperparameter Tuning (ClearML + Optuna)
Projekt obsuguje automatyczne poszukiwanie najlepszych parametr贸w (Learning Rate, Batch Size, Dropout, Architektura sieci). **Wymaga skonfigurowanego konta ClearML (clearml-init).**

**Dla modelu MLP**:
```bash
python -m models.tune --model mlp --trials ?
```

**Dla modelu CNN**:
```bash
python -m models.tune --model cnn --trials ?
```

## Wykorzystane Technologie i Techniki
* **TensorFlow/Keras**: Budowa i trening sieci neuronowych.
* **Librosa**: Przetwarzanie sygna贸w audio (MFCC, Mel-Spectrograms).
* **Scikit-learn**: PCA, skalowanie danych, metryki.
* **Optuna**: Zaawansowana optymalizacja hiperparametr贸w (TPE Sampler, Pruning).
* **ClearML**: ledzenie eksperyment贸w, logowanie metryk w chmurze.


* **Techniki ML**:
  * **PCA**
  * **Data Augmentation**
  * **Regularization** (Dropout, BatchNorm, Weight Decay, Early Stopping)
  * **Learning Rate Scheduler** (ReduceLROnPlateau)

